Amazon Web Services ブログ 経済産業省 GENIAC 基盤モデル開発支援事業 (第2期) における採択事業者への支援を開始 https://aws.amazon.com/jp/blogs/news/geniac-cycle2-kick-off/
2024年10月10日、経済産業省と国立研究開発法人新エネルギー・産業技術総合開発機構 (NEDO) が協力して実施する Generative AI Accelerator Challenge (GENIAC) の一環として実施している基盤モデル開発支援事業の第2期 (2024年7月公募) における採択事業者のキックオフが行われ、本事業の採択事業者が発表されました。
7月の AWS ブログでお伝えした通り、「経済産業省が計算リソース提供事業者から一括で確保し採択事業者へ提供する提供事業者」として AWS が選定され、同スキームを通じて NVIDIA H100 Tensor Core GPU を搭載する Amazon EC2 P5 インスタンス (p5.48xlarge) を提供します。また、「採択事業者が計算リソース提供事業者と個別に調整し直接確保」するスキームを通じて、上記 EC2 P5 インスタンスに加えて、採択事業者のニーズに合わせ Amazon SageMaker HyperPod および Amazon EC2 Trn1 インスタンスを提供することとなりました。
AWS は、計算リソース提供事業者として、GENIAC 支援チームを立ち上げたうえで以下の支援を提供します:
1. 計算資源: NVIDIA H100 Tensor Core GPU を搭載する Amazon EC2 P5 インスタンスまたは EC2 Trn1 インスタンスの提供
2. 技術支援: AWS Solutions Architect (SA) を中心としたメンバーにより、コンピュート (EC2)・ネットワーク (Elastic Fabric Adapter (EFA))・ストレージ (Amazon FSx for Lustre および Amazon S3) で構成される分散学習環境の AWS ParallelCluster や SageMaker HyperPod を活用した構築・管理の支援
3. 開発者コミュニティ: 海外の機械学習エンジニアとの交流による最先端の開発動向 (11月)、国内の機械学習エンジニア同士の交流による知見共有 (11月) をはじめとした国内外の知見共有に向けた支援
4. 事業化支援: GENIAC を通じて開発された基盤モデル・生成 AI アプリケーションの go-to-market 支援や AWS Marketplace の活用、利用企業との AWS 主催イベントを通じたマッチング機会の提供 (11月)
これらは、経済産業省商務情報政策局情報処理基盤産業室、NEDO、ボストン コンサルティング グループ (BCG)、および AWS パートナーであるクラスメソッド株式会社と密に連携のうえで提供されます。

採択事業者のうち AWS を利用する事業者は以下です (現時点で承諾が得られたもののみを掲載):
- AI inside株式会社
- AiHUB株式会社
- SyntheticGestalt株式会社
- Turing株式会社
- カラクリ株式会社
- ストックマーク株式会社
- フューチャー株式会社
- 株式会社EQUES
- 株式会社Preferred Elements
- 株式会社ヒューマノーム研究所
- 株式会社ユビタス
- 株式会社リコー
- 国立研究開発法人海洋研究開発機構

採択事業者からコメントを頂きました:
> 先端AIアーキテクチャを用いた処理においても信頼性高く稼働するインフラサービスを提供するAWS様に、技術/ビジネスの両面にていつもお世話になっております。GENIACサイクル2における大規模なAIモデルの学習処理においても、SageMaker HyperPodを活用することで円滑に開発が進むことを期待させていただければと思います。
> — ストックマーク株式会社 取締役CTO 有馬 幸介 氏

> この度インバウンド業務の課題を解決することを目的に、アジア言語対応の強化を目指したモデル開発において、モデル開発に弊社リソースを集中させ、効率的に開発が推進できるよう、基盤モデル構築に最適化されたマネージド型のインフラストラクチャを提供する Amazon SageMaker HyperPod を選択しました。今後AWSとAI活用に向けて更なる協業を期待しています。
> — 株式会社ユビタス CEO Wesley Kuo 氏

> AWSからは技術・ビジネスの両面でご支援いただき大変感謝しております。AWS Trainium は効率的にLLM開発を進めることができる最適な選択肢だと思っております。
> — カラクリ株式会社 取締役CPO 中山 智文 氏

> Preferred Networksグループでは、世界最大級の高品質なデータセットを構築し、私たちが開発する大規模言語モデル「PLaMo」のさらなる進化と社会実装に向けて取り組みます。 研究開発の効率化のため、Amazon EC2 P5インスタンスおよびAWS ParallelClusterを利用します。 AWSからの多大なサポートと革新的なソリューションに感謝いたします。
> — Preferred Networks 代表取締役 最高研究責任者, Preferred Elements 代表取締役社長 岡野原 大輔 氏

> AWSが提供するEC2 P5インスタンスおよびAWS ParallelClusterを活用し、完全自動運転の実現に向けた身体性をもつマルチモーダル基盤モデルの開発を進めていきます。現実の多様な運転環境に対応するため、独自の大規模走行データを新規に構築し、これをもとに複雑な交通状況を理解・予測できるモデルの開発を行います。AWSのスケーラブルなインフラにより、膨大なデータの処理と大規模モデルの学習を効率的に進め、短期間で高精度なモデルの実現を目指しています。
> — Turing株式会社 CTO 山口 祐 氏

> 地域または企業レベルで効果的な温暖化対策立案を目的とした気候サービスのための生成AI基盤モデル開発に当たり、大規模言語モデルを始めとした深層学習において高いパフォーマンスを発揮するNVIDIA H100 Tensor Core GPUを搭載したAmazon EC2 P5インスタンスを選択しました。基盤技術の開発から実用化・事業化、社会実装に向けた開発までが加速されることを期待しています。
> — 国立研究開発法人海洋研究開発機構 付加価値情報創生部門 地球情報科学技術センター データサイエンス研究グループ 松岡 大祐 氏

AWS では日本のお客様に対し、昨年の AWS LLM 開発支援プログラムにはじまり、 グローバルの Generative AI Accelerator や AWS ジャパン生成 AI 実用化推進プログラムといった取り組みを通して生成 AI ワークロードを支援しています。そこで得られた知見をもとに、GENIAC における日本の生成 AI 開発力向上に貢献できれば幸いです。